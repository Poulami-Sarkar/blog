---
title:  "Week12 Final"
date:   2019-08-19 
categories: post
---

[Link to my repository](https://www.github.com/Poulami-Sarkar/Bengali-Hindi-OCR)

My 12 weeks of working for Redhen lans is finally coming to a conclusion. Here's a brief summary of the work done and the challenges faced

## Project Description
My project was to develop a stable pipeline that performs OCR on videos from Hindi and Bengali news channels. My goal was to automatically detect all pieces of text that appear in the video and saving the same in the expected Redhen format.

## Process
I used EAST text detector for detecting the text from the videos. I have implemented the text detection in two parts. The first part involves detecting regions of text and then stitching together various detected regions to form words.
Since, the text detection is not language specific, it successfully detects text in all language. <br />

*NOTE: This functionality is a scalable solution for text detection that can be used for detecting text in any language from any video.* <br />
Example<br />
![Detected text regions](/blog/assets/article_images/7.png)<br />
![Stitched sentences](/blog/assets/article_images/6.png)<br />
[Code for text detection](https://github.com/Poulami-Sarkar/Bengali-Hindi-OCR/blob/master/textdetection_scalable.py)<br />

The next phase of the project was OCR. I have implemented this functionality using Tesseract4.0. This proved to be the most challenging part of the project as I have implemented this for 3 diiferent languages
(bengali, hindi,english). Since there was no means of deducing the language of the detected text, I ran the OCR assuming the text to be in multiple languages. This has significantly decreased the accuracy in cases where a single sentence consisted of text in more than one language <br />
![Example](/blog/assets/article_images/tick-220.jpg)<br />
OUTPUT: 'HORITY द्वारा जनहित में जारी www.iepf.govin @'<br />

[Code for OCR](https://github.com/Poulami-Sarkar/Bengali-Hindi-OCR/blob/master/scene.py)<br />
*NOTE:The bengali OCR can be further improved to increase the accuracy*

## Here's the final product
Demo for the final product will be updates shortly

## Submitting a slurm jobs on the HPC cluster
` sbatch <filename>.slurm `
<br />
The script used to submit the OCR code as a batch job can be found [here](https://github.com/Poulami-Sarkar/Bengali-Hindi-OCR/blob/master/test.slurm)<br />
Submit the job using ``` sbatch test.slurm ```
<br />
The maximum walltime for the main partition (queue) on the HPC server is 24 hours after which the job will automatically terminate. Since, my code is required to run periodically for new videos that are added to the server, I have made the job schedule itself before quitting. 
This functionality can be disabled by commenting the line 
``` sbatch test.slurm ```
as shown:<br />:
```shell
while [ 1 -eq 1 ]
do
	NOW=$( date '+%T' )
	if [ "$NOW" == "$TIME" ]
	then
        	#sbatch trial.slurm
	fi
done
echo 'exit'
```

## Future scope
A major challenge was that poor image quality especially in Bengali news videos leads to some small errors. <br />
[Example] Will be updated shortly <br />
Other minor errors can be corrected using Natural Language Processing. Sentence completion and correction can be done using deeplearning (RNN). As a future project, this has to be implemented separately for each language as well as for any case of combination of two or more languages.